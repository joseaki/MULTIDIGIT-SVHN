{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import json, codecs\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.hub import load_state_dict_from_url\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import random\n",
    "import glob\n",
    "import time\n",
    "import copy\n",
    "\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "from skimage import io, transform\n",
    "\n",
    "from skimage.transform import resize\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boxes(path, index, f):\n",
    "    boxes = []\n",
    "    labels = np.asarray([])\n",
    "    bbox_data = f[\"/digitStruct/bbox\"]\n",
    "    n_boxes = f[bbox_data[index][0]][\"label\"].len()\n",
    "    image_path = \"\"\n",
    "    if(n_boxes == 1):\n",
    "        box = {}\n",
    "        box['height'] = f[bbox_data[index][0]][\"height\"][0][0]\n",
    "        box['label'] = f[bbox_data[index][0]][\"label\"][0][0]\n",
    "        labels = np.append(labels,0) if (box['label'] == 10) else np.append(labels,box['label'])\n",
    "        box['left'] = f[bbox_data[index][0]][\"left\"][0][0]\n",
    "        box['top'] = f[bbox_data[index][0]][\"top\"][0][0]\n",
    "        box['width'] = f[bbox_data[index][0]][\"width\"][0][0]\n",
    "        box['name'] = str(index+1) + \".png\"\n",
    "        image_path = str(index+1) + \".png\"\n",
    "        boxes.append(box)\n",
    "    else:\n",
    "        for i in range(n_boxes):\n",
    "            box = {}\n",
    "            box['height'] = f[f[bbox_data[index][0]][\"height\"][i][0]][()][0][0]\n",
    "            box['label'] = f[f[bbox_data[index][0]][\"label\"][i][0]][()][0][0]\n",
    "            labels = np.append(labels,0) if (box['label'] == 10) else np.append(labels,box['label'])\n",
    "            box['left'] = f[f[bbox_data[index][0]][\"left\"][i][0]][()][0][0]\n",
    "            box['top'] = f[f[bbox_data[index][0]][\"top\"][i][0]][()][0][0]\n",
    "            box['width'] = f[f[bbox_data[index][0]][\"width\"][i][0]][()][0][0]\n",
    "            box['name'] = str(index+1) + \".png\"\n",
    "            image_path = str(index+1) + \".png\"\n",
    "            boxes.append(box)\n",
    "    image = io.imread(os.path.join(path,image_path))\n",
    "    bounds = get_borders(boxes)\n",
    "    y1 = int(bounds[1]) if int(bounds[1])>=0 else 0\n",
    "    x1 = int(bounds[3]) if int(bounds[3])>=0 else 0\n",
    "    y2 = int(bounds[0]) if int(bounds[0])>=0 else 0\n",
    "    x2 = int(bounds[2]) if int(bounds[2])>=0 else 0\n",
    "    image = image[y1:x1, y2:x2]\n",
    "    \n",
    "    image = np.multiply(resize(image, (64, 64)),255.0).tolist()\n",
    "    for i in range(5 - len(labels)):\n",
    "        labels = np.insert(labels, 0, 10, 0)\n",
    "    #image = torch.from_numpy(image)\n",
    "    #labels = torch.tensor(labels)\n",
    "    return image,labels,boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_SVHN(folder_path):\n",
    "    json_file = {}\n",
    "    print(\"loading data from \"+folder_path)\n",
    "    nh5 = len(glob.glob1(folder_path,\"*.h5\"))\n",
    "    try:\n",
    "        imgs, lbls  = read_many_hdf5(folder_path, 0)\n",
    "        for i in range(1,nh5):\n",
    "            images, labels  = read_many_hdf5(folder_path, i)\n",
    "            imgs = np.append(imgs,images, axis=0)\n",
    "            lbls = np.append(lbls,labels, axis=0)\n",
    "        data = [imgs,lbls]\n",
    "    except:\n",
    "        print(\"Archivo no existe, generando nuevos datos ...\")\n",
    "        data = read_data(folder_path)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    with h5py.File(path+\"/digitStruct.mat\", \"r\") as f:    \n",
    "        n_data = f[\"/digitStruct/bbox\"].len()\n",
    "        img_data = []\n",
    "        lbl_data = []\n",
    "        n=0\n",
    "        print(\"creando archivo de imagenes\")\n",
    "        for i in range(n_data):\n",
    "            image, label, boxes = get_boxes(path, i, f)\n",
    "            if(len(boxes)<=5):\n",
    "                img_data.append(image)\n",
    "                lbl_data.append(label)\n",
    "            if(i%10000==9999):\n",
    "                print(\"guardando archivo de iamgenes....\")\n",
    "                store_many_hdf5(img_data, lbl_data, path, n)\n",
    "                img_data = []\n",
    "                lbl_data = []\n",
    "                n = n + 1\n",
    "        store_many_hdf5(img_data, lbl_data, path, n)\n",
    "        \n",
    "        return img_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_many_hdf5(images, labels, path, name):\n",
    "    \"\"\" Stores an array of images to HDF5.\n",
    "        Parameters:\n",
    "        ---------------\n",
    "        images       images array, (N, 32, 32, 3) to be stored\n",
    "        labels       labels array, (N, 1) to be stored\n",
    "    \"\"\"\n",
    "    hdf5_dir = Path(path)\n",
    "    hdf5_dir.mkdir(parents=True, exist_ok=True)\n",
    "    num_images = len(images)\n",
    "\n",
    "    # Create a new HDF5 file\n",
    "    file = h5py.File(hdf5_dir / f\"{name}.h5\", \"w\")\n",
    "\n",
    "    # Create a dataset in the file\n",
    "    dataset = file.create_dataset(\n",
    "        \"images\", np.shape(images), h5py.h5t.STD_U8BE, data=images\n",
    "    )\n",
    "    meta_set = file.create_dataset(\n",
    "        \"meta\", np.shape(labels), h5py.h5t.STD_U8BE, data=labels\n",
    "    )\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_many_hdf5(path, name):\n",
    "    \"\"\" Reads image from HDF5.\n",
    "        Parameters:\n",
    "        ---------------\n",
    "        num_images   number of images to read\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        images      images array, (N, 32, 32, 3) to be stored\n",
    "        labels      associated meta data, int label (N, 1)\n",
    "    \"\"\"\n",
    "    hdf5_dir = Path(path)\n",
    "    hdf5_dir.mkdir(parents=True, exist_ok=True)\n",
    "    images, labels = [], []\n",
    "\n",
    "    # Open the HDF5 file\n",
    "    file = h5py.File(hdf5_dir / f\"{name}.h5\", \"r+\")\n",
    "\n",
    "    images = np.array(file[\"/images\"]).astype(\"uint8\")\n",
    "    labels = np.array(file[\"/meta\"]).astype(\"uint8\")\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_borders(img_data):\n",
    "    x1 = 9999999\n",
    "    y1 = 9999999\n",
    "    x2 = 0\n",
    "    y2 = 0\n",
    "    for box in img_data:\n",
    "        if(box[\"top\"]<y1): y1 = box[\"top\"] \n",
    "        if(box[\"left\"]<x1): x1 = box[\"left\"]\n",
    "        if(box[\"top\"] + box[\"height\"] > y2): y2 = box[\"top\"] + box[\"height\"]\n",
    "        if(box[\"left\"] + box[\"width\"] > x2): x2 = box[\"left\"] + box[\"width\"]\n",
    "\n",
    "    return [x1, y1, x2, y2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class svhn_dataset(Dataset):\n",
    "    def __init__(self, folder_path, transform = None):\n",
    "        self.folder_path = folder_path\n",
    "        self.data = load_SVHN(folder_path=folder_path)\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.data[1])\n",
    "    def __getitem__(self, idx):\n",
    "        #image = np.moveaxis(self.data[0][idx], -1, 0)\n",
    "        image = self.data[0][idx]\n",
    "        labels = self.data[1][idx]\n",
    "        if(self.transform):\n",
    "            image = self.transform(image)\n",
    "        sample = {\"image\": image, \"labels\": torch.tensor(labels)}\n",
    "        return(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class toPIL(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, image):\n",
    "        # swap color axis because\n",
    "        # numpy image: C x H x W\n",
    "        # torch image: C X H X W\n",
    "        #image = image.transpose((2, 0, 1))\n",
    "        # print(other[0][\"name\"],labels)\n",
    "        image = Image.fromarray(image, mode=\"RGB\")\n",
    "        \n",
    "        #image = TF.normalize(image,mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from ./data/SVHN/test\n"
     ]
    }
   ],
   "source": [
    "test_dataset = svhn_dataset(\"./data/SVHN/test\",transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                                             transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from ./data/SVHN/train\n"
     ]
    }
   ],
   "source": [
    "train_dataset = svhn_dataset(\"./data/SVHN/train\",transform=transforms.Compose([toPIL(),\n",
    "                                                                               transforms.RandomChoice([\n",
    "                                                                                   transforms.ColorJitter(brightness=[0.5,0.8],\n",
    "                                                                                                          contrast=[0.4,0.5],\n",
    "                                                                                                          saturation=[0,1]),\n",
    "                                                                                   transforms.RandomRotation(degrees=30)\n",
    "                                                                               ]),\n",
    "                                                                               transforms.ColorJitter(hue=[-0.5,0.5]),\n",
    "                                                                               transforms.ToTensor(),\n",
    "                                                                               transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "                                                                              ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from ./data/SVHN/extra\n"
     ]
    }
   ],
   "source": [
    "extra_dataset = svhn_dataset(\"./data/SVHN/extra\",transform=transforms.Compose([\n",
    "                                                                               transforms.ToTensor(),\n",
    "                                                                               transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "                                                                              ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size = 256, num_workers = 0, shuffle = True, drop_last = True)\n",
    "validation_loader = DataLoader(test_dataset, batch_size = 256, num_workers = 0, shuffle = True, drop_last = True)\n",
    "test_loader = DataLoader(extra_dataset, batch_size = 128, num_workers = 0, shuffle = True, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set has 130 batches \n",
      "validation set has 51 batches \n",
      "test set has 1580 batches \n"
     ]
    }
   ],
   "source": [
    "print(\"training set has {} batches \".format(len(train_loader)))\n",
    "print(\"validation set has {} batches \".format(len(validation_loader)))\n",
    "print(\"test set has {} batches \".format(len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.2445, -1.2274, -1.2274,  ..., -1.3302, -1.3302, -1.3130],\n",
      "         [-1.2445, -1.2274, -1.2274,  ..., -1.3302, -1.3302, -1.3302],\n",
      "         [-1.2445, -1.2274, -1.2274,  ..., -1.3302, -1.3302, -1.3302],\n",
      "         ...,\n",
      "         [-1.2445, -1.2274, -1.2274,  ..., -1.3644, -1.3473, -1.3302],\n",
      "         [-1.2617, -1.2445, -1.2274,  ..., -1.3473, -1.3302, -1.3302],\n",
      "         [-1.2617, -1.2445, -1.2274,  ..., -1.3473, -1.3302, -1.3130]],\n",
      "\n",
      "        [[-1.1078, -1.0903, -1.0728,  ..., -1.2129, -1.1954, -1.1779],\n",
      "         [-1.1078, -1.0903, -1.0728,  ..., -1.2304, -1.1954, -1.1779],\n",
      "         [-1.1078, -1.0728, -1.0728,  ..., -1.2304, -1.1954, -1.1779],\n",
      "         ...,\n",
      "         [-1.0903, -1.0728, -1.0728,  ..., -1.1779, -1.1779, -1.1604],\n",
      "         [-1.0903, -1.0903, -1.0728,  ..., -1.1779, -1.1604, -1.1429],\n",
      "         [-1.0903, -1.0903, -1.0903,  ..., -1.1604, -1.1429, -1.1253]],\n",
      "\n",
      "        [[-0.8981, -0.8807, -0.8458,  ..., -0.9853, -0.9678, -0.9504],\n",
      "         [-0.8981, -0.8807, -0.8458,  ..., -1.0027, -0.9853, -0.9504],\n",
      "         [-0.8981, -0.8807, -0.8458,  ..., -1.0027, -0.9853, -0.9504],\n",
      "         ...,\n",
      "         [-0.8458, -0.8458, -0.8458,  ..., -0.9853, -0.9504, -0.9678],\n",
      "         [-0.8458, -0.8458, -0.8458,  ..., -0.9504, -0.9678, -0.9504],\n",
      "         [-0.8458, -0.8458, -0.8458,  ..., -0.9678, -0.9504, -0.9330]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1aca6382c88>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = train_dataset[26][\"image\"]\n",
    "print(image)\n",
    "plt.figure()\n",
    "plt.imshow(image.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "__all__ = [\n",
    "    'VGG', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn',\n",
    "    'vgg19_bn', 'vgg19',\n",
    "]\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\n",
    "    'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\n",
    "    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\n",
    "    'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\n",
    "    'vgg11_bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',\n",
    "    'vgg13_bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',\n",
    "    'vgg16_bn': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth',\n",
    "    'vgg19_bn': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',\n",
    "}\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "\n",
    "    def __init__(self, features, num_classes=11, init_weights=True):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((2, 2))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 2 * 2, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "        )\n",
    "        self.fcd1 = nn.Linear(4096, num_classes)\n",
    "        self.fcd2 = nn.Linear(4096, num_classes)\n",
    "        self.fcd3 = nn.Linear(4096, num_classes)\n",
    "        self.fcd4 = nn.Linear(4096, num_classes)\n",
    "        self.fcd5 = nn.Linear(4096, num_classes)\n",
    "        self.sig1 = nn.LogSoftmax(dim=1)\n",
    "        self.sig2 = nn.LogSoftmax(dim=1)\n",
    "        self.sig3 = nn.LogSoftmax(dim=1)\n",
    "        self.sig4 = nn.LogSoftmax(dim=1)\n",
    "        self.sig5 = nn.LogSoftmax(dim=1)\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        dig1 = self.sig1(self.fcd1(x))\n",
    "        dig2 = self.sig1(self.fcd2(x))\n",
    "        dig3 = self.sig1(self.fcd3(x))\n",
    "        dig4 = self.sig1(self.fcd4(x))\n",
    "        dig5 = self.sig1(self.fcd5(x))\n",
    "        resp = torch.stack([dig1, dig2, dig3, dig4, dig5],2) \n",
    "        return resp\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "cfgs = {\n",
    "    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "def _vgg(arch, cfg, batch_norm, pretrained, progress, **kwargs):\n",
    "    if pretrained:\n",
    "        kwargs['init_weights'] = False\n",
    "    model = VGG(make_layers(cfgs[cfg], batch_norm=batch_norm), **kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
    "                                              progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg11(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"VGG 11-layer model (configuration \"A\") from\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _vgg('vgg11', 'A', False, pretrained, progress, **kwargs)\n",
    "\n",
    "\n",
    "def vgg11_bn(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"VGG 11-layer model (configuration \"A\") with batch normalization\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _vgg('vgg11_bn', 'A', True, pretrained, progress, **kwargs)\n",
    "\n",
    "\n",
    "def vgg13(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"VGG 13-layer model (configuration \"B\")\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _vgg('vgg13', 'B', False, pretrained, progress, **kwargs)\n",
    "\n",
    "\n",
    "def vgg13_bn(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _vgg('vgg13_bn', 'B', True, pretrained, progress, **kwargs)\n",
    "\n",
    "\n",
    "def vgg16(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"VGG 16-layer model (configuration \"D\")\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _vgg('vgg16', 'D', False, pretrained, progress, **kwargs)\n",
    "\n",
    "\n",
    "def vgg16_bn(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"VGG 16-layer model (configuration \"D\") with batch normalization\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _vgg('vgg16_bn', 'D', True, pretrained, progress, **kwargs)\n",
    "\n",
    "\n",
    "def vgg19(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"VGG 19-layer model (configuration \"E\")\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _vgg('vgg19', 'E', False, pretrained, progress, **kwargs)\n",
    "\n",
    "\n",
    "def vgg19_bn(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"VGG 19-layer model (configuration 'E') with batch normalization\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _vgg('vgg19_bn', 'E', True, pretrained, progress, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for idx, data in enumerate(dataloaders[phase]):\n",
    "                inputs = data[\"image\"].to(device, dtype=torch.float)\n",
    "                labels = data[\"labels\"].to(device, dtype=torch.long)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    \n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    _,preds = torch.max(outputs, 1)#outputs.data.max(1, keepdim=False) #outputs.data.max(2, keepdim=False)[1].reshape(-1,5).float()\n",
    "                    \n",
    "                   \n",
    "                    if(idx == 20 and phase == 'val' ):\n",
    "                        #p = pd.DataFrame(outputs[0,:,:].cpu().detach().numpy())\n",
    "                        #display(p)\n",
    "                        print(\"Predicciones\",preds[0,:])\n",
    "                        print(\"Real .......\",labels[0,:])\n",
    "                    #_, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += preds.eq(labels).sum() #torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU(inplace=True)\n",
      "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (24): ReLU(inplace=True)\n",
      "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(2, 2))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (fcd1): Linear(in_features=4096, out_features=11, bias=True)\n",
      "  (fcd2): Linear(in_features=4096, out_features=11, bias=True)\n",
      "  (fcd3): Linear(in_features=4096, out_features=11, bias=True)\n",
      "  (fcd4): Linear(in_features=4096, out_features=11, bias=True)\n",
      "  (fcd5): Linear(in_features=4096, out_features=11, bias=True)\n",
      "  (sig1): LogSoftmax()\n",
      "  (sig2): LogSoftmax()\n",
      "  (sig3): LogSoftmax()\n",
      "  (sig4): LogSoftmax()\n",
      "  (sig5): LogSoftmax()\n",
      ")\n",
      "Params to learn:\n",
      "\t features.0.weight\n",
      "\t features.0.bias\n",
      "\t features.1.weight\n",
      "\t features.1.bias\n",
      "\t features.4.weight\n",
      "\t features.4.bias\n",
      "\t features.5.weight\n",
      "\t features.5.bias\n",
      "\t features.8.weight\n",
      "\t features.8.bias\n",
      "\t features.9.weight\n",
      "\t features.9.bias\n",
      "\t features.11.weight\n",
      "\t features.11.bias\n",
      "\t features.12.weight\n",
      "\t features.12.bias\n",
      "\t features.15.weight\n",
      "\t features.15.bias\n",
      "\t features.16.weight\n",
      "\t features.16.bias\n",
      "\t features.18.weight\n",
      "\t features.18.bias\n",
      "\t features.19.weight\n",
      "\t features.19.bias\n",
      "\t features.22.weight\n",
      "\t features.22.bias\n",
      "\t features.23.weight\n",
      "\t features.23.bias\n",
      "\t features.25.weight\n",
      "\t features.25.bias\n",
      "\t features.26.weight\n",
      "\t features.26.bias\n",
      "\t classifier.0.weight\n",
      "\t classifier.0.bias\n",
      "\t classifier.3.weight\n",
      "\t classifier.3.bias\n",
      "\t fcd1.weight\n",
      "\t fcd1.bias\n",
      "\t fcd2.weight\n",
      "\t fcd2.bias\n",
      "\t fcd3.weight\n",
      "\t fcd3.bias\n",
      "\t fcd4.weight\n",
      "\t fcd4.bias\n",
      "\t fcd5.weight\n",
      "\t fcd5.bias\n",
      "Epoch 0/149\n",
      "----------\n",
      "train Loss: 1.1814 Acc: 2.9510\n",
      "Predicciones tensor([10, 10, 10, 10,  1], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  1,  3], device='cuda:0')\n",
      "val Loss: 0.9367 Acc: 3.3277\n",
      "\n",
      "Epoch 1/149\n",
      "----------\n",
      "train Loss: 1.0029 Acc: 3.2477\n",
      "Predicciones tensor([10, 10, 10,  2,  2], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  9,  2], device='cuda:0')\n",
      "val Loss: 0.7361 Acc: 3.7350\n",
      "\n",
      "Epoch 2/149\n",
      "----------\n",
      "train Loss: 0.7367 Acc: 3.7290\n",
      "Predicciones tensor([10, 10, 10, 10,  2], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10, 10,  9], device='cuda:0')\n",
      "val Loss: 0.4737 Acc: 4.2309\n",
      "\n",
      "Epoch 3/149\n",
      "----------\n",
      "train Loss: 0.5256 Acc: 4.1085\n",
      "Predicciones tensor([10, 10, 10, 10,  4], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10, 10,  4], device='cuda:0')\n",
      "val Loss: 0.3537 Acc: 4.4451\n",
      "\n",
      "Epoch 4/149\n",
      "----------\n",
      "train Loss: 0.4128 Acc: 4.3124\n",
      "Predicciones tensor([10, 10, 10,  3,  3], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  3,  3], device='cuda:0')\n",
      "val Loss: 0.2887 Acc: 4.5452\n",
      "\n",
      "Epoch 5/149\n",
      "----------\n",
      "train Loss: 0.3384 Acc: 4.4388\n",
      "Predicciones tensor([10, 10, 10,  3,  3], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  5,  5], device='cuda:0')\n",
      "val Loss: 0.2382 Acc: 4.6293\n",
      "\n",
      "Epoch 6/149\n",
      "----------\n",
      "train Loss: 0.2938 Acc: 4.5082\n",
      "Predicciones tensor([10, 10, 10, 10,  8], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10, 10,  8], device='cuda:0')\n",
      "val Loss: 0.2205 Acc: 4.6611\n",
      "\n",
      "Epoch 7/149\n",
      "----------\n",
      "train Loss: 0.2575 Acc: 4.5710\n",
      "Predicciones tensor([10, 10, 10,  4,  4], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  4,  4], device='cuda:0')\n",
      "val Loss: 0.2172 Acc: 4.6689\n",
      "\n",
      "Epoch 8/149\n",
      "----------\n",
      "train Loss: 0.2325 Acc: 4.6088\n",
      "Predicciones tensor([10, 10, 10,  1,  2], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  1,  2], device='cuda:0')\n",
      "val Loss: 0.2063 Acc: 4.6818\n",
      "\n",
      "Epoch 9/149\n",
      "----------\n",
      "train Loss: 0.2091 Acc: 4.6511\n",
      "Predicciones tensor([10, 10, 10,  2,  5], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  2,  5], device='cuda:0')\n",
      "val Loss: 0.1795 Acc: 4.7311\n",
      "\n",
      "Epoch 10/149\n",
      "----------\n",
      "train Loss: 0.1909 Acc: 4.6791\n",
      "Predicciones tensor([10, 10, 10, 10,  9], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10, 10,  9], device='cuda:0')\n",
      "val Loss: 0.1875 Acc: 4.7254\n",
      "\n",
      "Epoch 11/149\n",
      "----------\n",
      "train Loss: 0.1784 Acc: 4.6988\n",
      "Predicciones tensor([10, 10, 10, 10,  1], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10, 10,  7], device='cuda:0')\n",
      "val Loss: 0.1745 Acc: 4.7382\n",
      "\n",
      "Epoch 12/149\n",
      "----------\n",
      "train Loss: 0.1634 Acc: 4.7233\n",
      "Predicciones tensor([10, 10, 10,  2,  5], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  2,  5], device='cuda:0')\n",
      "val Loss: 0.1885 Acc: 4.7304\n",
      "\n",
      "Epoch 13/149\n",
      "----------\n",
      "train Loss: 0.1491 Acc: 4.7453\n",
      "Predicciones tensor([10, 10, 10, 10,  8], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10, 10,  8], device='cuda:0')\n",
      "val Loss: 0.1793 Acc: 4.7415\n",
      "\n",
      "Epoch 14/149\n",
      "----------\n",
      "train Loss: 0.1360 Acc: 4.7653\n",
      "Predicciones tensor([10, 10, 10,  2,  9], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  2,  3], device='cuda:0')\n",
      "val Loss: 0.1880 Acc: 4.7394\n",
      "\n",
      "Epoch 15/149\n",
      "----------\n",
      "train Loss: 0.1289 Acc: 4.7762\n",
      "Predicciones tensor([10, 10, 10,  3,  0], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  3,  0], device='cuda:0')\n",
      "val Loss: 0.1790 Acc: 4.7521\n",
      "\n",
      "Epoch 16/149\n",
      "----------\n",
      "train Loss: 0.1188 Acc: 4.7897\n",
      "Predicciones tensor([10, 10, 10,  1,  6], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  1,  6], device='cuda:0')\n",
      "val Loss: 0.2025 Acc: 4.7271\n",
      "\n",
      "Epoch 17/149\n",
      "----------\n",
      "train Loss: 0.1126 Acc: 4.8037\n",
      "Predicciones tensor([10, 10, 10, 10,  4], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10, 10,  4], device='cuda:0')\n",
      "val Loss: 0.1852 Acc: 4.7533\n",
      "\n",
      "Epoch 18/149\n",
      "----------\n",
      "train Loss: 0.1032 Acc: 4.8176\n",
      "Predicciones tensor([10, 10, 10,  3,  2], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  3,  2], device='cuda:0')\n",
      "val Loss: 0.1823 Acc: 4.7564\n",
      "\n",
      "Epoch 19/149\n",
      "----------\n",
      "train Loss: 0.0994 Acc: 4.8201\n",
      "Predicciones tensor([10, 10, 10,  1,  5], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  1,  5], device='cuda:0')\n",
      "val Loss: 0.1981 Acc: 4.7533\n",
      "\n",
      "Epoch 20/149\n",
      "----------\n",
      "train Loss: 0.0913 Acc: 4.8352\n",
      "Predicciones tensor([10, 10, 10, 10,  3], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10, 10,  3], device='cuda:0')\n",
      "val Loss: 0.2151 Acc: 4.7309\n",
      "\n",
      "Epoch 21/149\n",
      "----------\n",
      "train Loss: 0.0869 Acc: 4.8423\n",
      "Predicciones tensor([10, 10, 10,  5,  8], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  5,  8], device='cuda:0')\n",
      "val Loss: 0.1893 Acc: 4.7753\n",
      "\n",
      "Epoch 22/149\n",
      "----------\n",
      "train Loss: 0.0804 Acc: 4.8519\n",
      "Predicciones tensor([10, 10, 10,  4,  0], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  4,  0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2047 Acc: 4.7430\n",
      "\n",
      "Epoch 23/149\n",
      "----------\n",
      "train Loss: 0.0775 Acc: 4.8568\n",
      "Predicciones tensor([10, 10,  1,  4,  8], device='cuda:0')\n",
      "Real ....... tensor([10, 10,  1,  4,  8], device='cuda:0')\n",
      "val Loss: 0.1921 Acc: 4.7769\n",
      "\n",
      "Epoch 24/149\n",
      "----------\n",
      "train Loss: 0.0742 Acc: 4.8611\n",
      "Predicciones tensor([10, 10, 10,  2,  3], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  2,  3], device='cuda:0')\n",
      "val Loss: 0.1955 Acc: 4.7678\n",
      "\n",
      "Epoch 25/149\n",
      "----------\n",
      "train Loss: 0.0709 Acc: 4.8679\n",
      "Predicciones tensor([10, 10, 10,  3,  0], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  3,  0], device='cuda:0')\n",
      "val Loss: 0.2167 Acc: 4.7548\n",
      "\n",
      "Epoch 26/149\n",
      "----------\n",
      "train Loss: 0.0656 Acc: 4.8774\n",
      "Predicciones tensor([10, 10, 10, 10,  5], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10, 10,  5], device='cuda:0')\n",
      "val Loss: 0.1877 Acc: 4.7788\n",
      "\n",
      "Epoch 27/149\n",
      "----------\n",
      "train Loss: 0.0640 Acc: 4.8781\n",
      "Predicciones tensor([10, 10, 10,  1,  6], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  1,  6], device='cuda:0')\n",
      "val Loss: 0.1997 Acc: 4.7760\n",
      "\n",
      "Epoch 28/149\n",
      "----------\n",
      "train Loss: 0.0597 Acc: 4.8836\n",
      "Predicciones tensor([10, 10, 10,  6,  2], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  8,  2], device='cuda:0')\n",
      "val Loss: 0.2162 Acc: 4.7570\n",
      "\n",
      "Epoch 29/149\n",
      "----------\n",
      "train Loss: 0.0569 Acc: 4.8916\n",
      "Predicciones tensor([10, 10, 10,  1,  7], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  1,  7], device='cuda:0')\n",
      "val Loss: 0.1921 Acc: 4.7911\n",
      "\n",
      "Epoch 30/149\n",
      "----------\n",
      "train Loss: 0.0552 Acc: 4.8949\n",
      "Predicciones tensor([10, 10, 10,  8,  4], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  8,  4], device='cuda:0')\n",
      "val Loss: 0.1998 Acc: 4.7818\n",
      "\n",
      "Epoch 31/149\n",
      "----------\n",
      "train Loss: 0.0521 Acc: 4.8979\n",
      "Predicciones tensor([10, 10, 10, 10,  1], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10, 10,  1], device='cuda:0')\n",
      "val Loss: 0.2348 Acc: 4.7481\n",
      "\n",
      "Epoch 32/149\n",
      "----------\n",
      "train Loss: 0.0494 Acc: 4.9017\n",
      "Predicciones tensor([10, 10, 10, 10,  3], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10, 10,  7], device='cuda:0')\n",
      "val Loss: 0.2179 Acc: 4.7679\n",
      "\n",
      "Epoch 33/149\n",
      "----------\n",
      "train Loss: 0.0462 Acc: 4.9070\n",
      "Predicciones tensor([10, 10, 10,  2,  8], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  2,  8], device='cuda:0')\n",
      "val Loss: 0.2168 Acc: 4.7720\n",
      "\n",
      "Epoch 34/149\n",
      "----------\n",
      "train Loss: 0.0463 Acc: 4.9057\n",
      "Predicciones tensor([10, 10,  1,  4,  6], device='cuda:0')\n",
      "Real ....... tensor([10, 10,  1,  4,  5], device='cuda:0')\n",
      "val Loss: 0.2113 Acc: 4.7810\n",
      "\n",
      "Epoch 35/149\n",
      "----------\n",
      "train Loss: 0.0461 Acc: 4.9069\n",
      "Predicciones tensor([10, 10, 10,  3,  4], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  3,  4], device='cuda:0')\n",
      "val Loss: 0.2016 Acc: 4.7821\n",
      "\n",
      "Epoch 36/149\n",
      "----------\n",
      "train Loss: 0.0434 Acc: 4.9107\n",
      "Predicciones tensor([10, 10, 10,  4,  4], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  4,  4], device='cuda:0')\n",
      "val Loss: 0.2118 Acc: 4.7891\n",
      "\n",
      "Epoch 37/149\n",
      "----------\n",
      "train Loss: 0.0427 Acc: 4.9114\n",
      "Predicciones tensor([10, 10, 10,  5,  4], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  5,  4], device='cuda:0')\n",
      "val Loss: 0.2161 Acc: 4.7786\n",
      "\n",
      "Epoch 38/149\n",
      "----------\n",
      "train Loss: 0.0450 Acc: 4.9078\n",
      "Predicciones tensor([10, 10, 10,  9,  0], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  9,  0], device='cuda:0')\n",
      "val Loss: 0.2179 Acc: 4.7808\n",
      "\n",
      "Epoch 39/149\n",
      "----------\n",
      "train Loss: 0.0395 Acc: 4.9182\n",
      "Predicciones tensor([10, 10,  1,  0,  9], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  1,  9], device='cuda:0')\n",
      "val Loss: 0.2132 Acc: 4.7851\n",
      "\n",
      "Epoch 40/149\n",
      "----------\n",
      "train Loss: 0.0362 Acc: 4.9223\n",
      "Predicciones tensor([10, 10, 10,  3,  1], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  3,  1], device='cuda:0')\n",
      "val Loss: 0.2469 Acc: 4.7691\n",
      "\n",
      "Epoch 41/149\n",
      "----------\n",
      "train Loss: 0.0412 Acc: 4.9149\n",
      "Predicciones tensor([10, 10, 10, 10,  2], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10, 10,  9], device='cuda:0')\n",
      "val Loss: 0.2178 Acc: 4.7733\n",
      "\n",
      "Epoch 42/149\n",
      "----------\n",
      "train Loss: 0.0363 Acc: 4.9227\n",
      "Predicciones tensor([10, 10, 10, 10,  4], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10, 10,  4], device='cuda:0')\n",
      "val Loss: 0.2372 Acc: 4.7673\n",
      "\n",
      "Epoch 43/149\n",
      "----------\n",
      "train Loss: 0.0359 Acc: 4.9240\n",
      "Predicciones tensor([10, 10,  1,  2,  6], device='cuda:0')\n",
      "Real ....... tensor([10, 10,  1,  2,  6], device='cuda:0')\n",
      "val Loss: 0.2337 Acc: 4.7775\n",
      "\n",
      "Epoch 44/149\n",
      "----------\n",
      "train Loss: 0.0372 Acc: 4.9201\n",
      "Predicciones tensor([10, 10, 10, 10,  5], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10, 10,  5], device='cuda:0')\n",
      "val Loss: 0.2403 Acc: 4.7644\n",
      "\n",
      "Epoch 45/149\n",
      "----------\n",
      "train Loss: 0.0329 Acc: 4.9295\n",
      "Predicciones tensor([10, 10, 10,  3,  9], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  3,  8], device='cuda:0')\n",
      "val Loss: 0.2127 Acc: 4.8003\n",
      "\n",
      "Epoch 46/149\n",
      "----------\n",
      "train Loss: 0.0316 Acc: 4.9299\n",
      "Predicciones tensor([10, 10, 10,  1,  9], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  1,  9], device='cuda:0')\n",
      "val Loss: 0.2291 Acc: 4.7868\n",
      "\n",
      "Epoch 47/149\n",
      "----------\n",
      "train Loss: 0.0322 Acc: 4.9292\n",
      "Predicciones tensor([10, 10, 10,  3,  7], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  6,  7], device='cuda:0')\n",
      "val Loss: 0.2344 Acc: 4.7779\n",
      "\n",
      "Epoch 48/149\n",
      "----------\n",
      "train Loss: 0.0302 Acc: 4.9321\n",
      "Predicciones tensor([10, 10, 10,  7,  8], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  7,  8], device='cuda:0')\n",
      "val Loss: 0.2307 Acc: 4.7909\n",
      "\n",
      "Epoch 49/149\n",
      "----------\n",
      "train Loss: 0.0311 Acc: 4.9311\n",
      "Predicciones tensor([10, 10,  1,  9,  0], device='cuda:0')\n",
      "Real ....... tensor([10, 10,  1,  9,  0], device='cuda:0')\n",
      "val Loss: 0.2436 Acc: 4.7775\n",
      "\n",
      "Epoch 50/149\n",
      "----------\n",
      "train Loss: 0.0295 Acc: 4.9327\n",
      "Predicciones tensor([10, 10, 10,  2,  1], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  2,  1], device='cuda:0')\n",
      "val Loss: 0.2470 Acc: 4.7772\n",
      "\n",
      "Epoch 51/149\n",
      "----------\n",
      "train Loss: 0.0269 Acc: 4.9380\n",
      "Predicciones tensor([10, 10, 10, 10,  1], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10, 10,  1], device='cuda:0')\n",
      "val Loss: 0.2604 Acc: 4.7733\n",
      "\n",
      "Epoch 52/149\n",
      "----------\n",
      "train Loss: 0.0274 Acc: 4.9370\n",
      "Predicciones tensor([10, 10, 10,  5,  9], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  5,  9], device='cuda:0')\n",
      "val Loss: 0.2376 Acc: 4.7899\n",
      "\n",
      "Epoch 53/149\n",
      "----------\n",
      "train Loss: 0.0276 Acc: 4.9353\n",
      "Predicciones tensor([10, 10, 10,  2,  9], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  2,  0], device='cuda:0')\n",
      "val Loss: 0.2416 Acc: 4.7713\n",
      "\n",
      "Epoch 54/149\n",
      "----------\n",
      "train Loss: 0.0270 Acc: 4.9377\n",
      "Predicciones tensor([10, 10, 10, 10,  7], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  6,  7], device='cuda:0')\n",
      "val Loss: 0.2397 Acc: 4.7909\n",
      "\n",
      "Epoch 55/149\n",
      "----------\n",
      "train Loss: 0.0273 Acc: 4.9363\n",
      "Predicciones tensor([10, 10, 10,  2,  4], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  2,  4], device='cuda:0')\n",
      "val Loss: 0.2313 Acc: 4.7936\n",
      "\n",
      "Epoch 56/149\n",
      "----------\n",
      "train Loss: 0.0249 Acc: 4.9413\n",
      "Predicciones tensor([10, 10,  8,  4,  3], device='cuda:0')\n",
      "Real ....... tensor([10, 10,  8,  4,  3], device='cuda:0')\n",
      "val Loss: 0.2395 Acc: 4.7860\n",
      "\n",
      "Epoch 57/149\n",
      "----------\n",
      "train Loss: 0.0255 Acc: 4.9390\n",
      "Predicciones tensor([10, 10, 10,  3,  6], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  3,  6], device='cuda:0')\n",
      "val Loss: 0.2429 Acc: 4.7867\n",
      "\n",
      "Epoch 58/149\n",
      "----------\n",
      "train Loss: 0.0248 Acc: 4.9413\n",
      "Predicciones tensor([10, 10,  2,  3,  4], device='cuda:0')\n",
      "Real ....... tensor([10, 10,  2,  2,  4], device='cuda:0')\n",
      "val Loss: 0.2326 Acc: 4.7929\n",
      "\n",
      "Epoch 59/149\n",
      "----------\n",
      "train Loss: 0.0237 Acc: 4.9411\n",
      "Predicciones tensor([10, 10, 10,  2,  2], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  2,  2], device='cuda:0')\n",
      "val Loss: 0.2648 Acc: 4.7793\n",
      "\n",
      "Epoch 60/149\n",
      "----------\n",
      "train Loss: 0.0256 Acc: 4.9396\n",
      "Predicciones tensor([10, 10, 10,  6,  8], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  5,  8], device='cuda:0')\n",
      "val Loss: 0.2167 Acc: 4.7976\n",
      "\n",
      "Epoch 61/149\n",
      "----------\n",
      "train Loss: 0.0232 Acc: 4.9438\n",
      "Predicciones tensor([10, 10, 10, 10,  3], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10, 10,  3], device='cuda:0')\n",
      "val Loss: 0.2515 Acc: 4.7835\n",
      "\n",
      "Epoch 62/149\n",
      "----------\n",
      "train Loss: 0.0210 Acc: 4.9467\n",
      "Predicciones tensor([10, 10, 10,  1,  2], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  1,  2], device='cuda:0')\n",
      "val Loss: 0.2627 Acc: 4.7890\n",
      "\n",
      "Epoch 63/149\n",
      "----------\n",
      "train Loss: 0.0230 Acc: 4.9444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones tensor([10, 10,  1,  1,  0], device='cuda:0')\n",
      "Real ....... tensor([10, 10,  1,  1,  0], device='cuda:0')\n",
      "val Loss: 0.2630 Acc: 4.7724\n",
      "\n",
      "Epoch 64/149\n",
      "----------\n",
      "train Loss: 0.0207 Acc: 4.9479\n",
      "Predicciones tensor([10, 10, 10,  8,  9], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  8,  9], device='cuda:0')\n",
      "val Loss: 0.2496 Acc: 4.7867\n",
      "\n",
      "Epoch 65/149\n",
      "----------\n",
      "train Loss: 0.0231 Acc: 4.9428\n",
      "Predicciones tensor([10, 10, 10,  3,  9], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  3,  9], device='cuda:0')\n",
      "val Loss: 0.2530 Acc: 4.7808\n",
      "\n",
      "Epoch 66/149\n",
      "----------\n",
      "train Loss: 0.0220 Acc: 4.9455\n",
      "Predicciones tensor([10, 10, 10,  2,  4], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  2,  4], device='cuda:0')\n",
      "val Loss: 0.2546 Acc: 4.7785\n",
      "\n",
      "Epoch 67/149\n",
      "----------\n",
      "train Loss: 0.0207 Acc: 4.9470\n",
      "Predicciones tensor([10, 10, 10,  2,  4], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  2,  4], device='cuda:0')\n",
      "val Loss: 0.2483 Acc: 4.7859\n",
      "\n",
      "Epoch 68/149\n",
      "----------\n",
      "train Loss: 0.0201 Acc: 4.9480\n",
      "Predicciones tensor([10, 10, 10,  3,  4], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  3,  4], device='cuda:0')\n",
      "val Loss: 0.2470 Acc: 4.7873\n",
      "\n",
      "Epoch 69/149\n",
      "----------\n",
      "train Loss: 0.0199 Acc: 4.9478\n",
      "Predicciones tensor([10, 10,  1,  1,  4], device='cuda:0')\n",
      "Real ....... tensor([10, 10,  1,  1,  1], device='cuda:0')\n",
      "val Loss: 0.2607 Acc: 4.7919\n",
      "\n",
      "Epoch 70/149\n",
      "----------\n",
      "train Loss: 0.0206 Acc: 4.9474\n",
      "Predicciones tensor([10, 10, 10,  2,  9], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  2,  9], device='cuda:0')\n",
      "val Loss: 0.2747 Acc: 4.7832\n",
      "\n",
      "Epoch 71/149\n",
      "----------\n",
      "train Loss: 0.0217 Acc: 4.9451\n",
      "Predicciones tensor([10, 10, 10,  9,  8], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  9,  8], device='cuda:0')\n",
      "val Loss: 0.2462 Acc: 4.7898\n",
      "\n",
      "Epoch 72/149\n",
      "----------\n",
      "train Loss: 0.0195 Acc: 4.9495\n",
      "Predicciones tensor([10, 10,  2,  1,  3], device='cuda:0')\n",
      "Real ....... tensor([10, 10,  2,  1,  3], device='cuda:0')\n",
      "val Loss: 0.2480 Acc: 4.7924\n",
      "\n",
      "Epoch 73/149\n",
      "----------\n",
      "train Loss: 0.0191 Acc: 4.9508\n",
      "Predicciones tensor([10, 10, 10, 10,  1], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10, 10,  1], device='cuda:0')\n",
      "val Loss: 0.2537 Acc: 4.7958\n",
      "\n",
      "Epoch 74/149\n",
      "----------\n",
      "train Loss: 0.0207 Acc: 4.9485\n",
      "Predicciones tensor([10, 10, 10,  6,  2], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  8,  2], device='cuda:0')\n",
      "val Loss: 0.2519 Acc: 4.7894\n",
      "\n",
      "Epoch 75/149\n",
      "----------\n",
      "train Loss: 0.0183 Acc: 4.9523\n",
      "Predicciones tensor([10, 10, 10,  9,  8], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  9,  8], device='cuda:0')\n",
      "val Loss: 0.2752 Acc: 4.7756\n",
      "\n",
      "Epoch 76/149\n",
      "----------\n",
      "train Loss: 0.0192 Acc: 4.9499\n",
      "Predicciones tensor([10, 10, 10,  3,  7], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  2,  7], device='cuda:0')\n",
      "val Loss: 0.2607 Acc: 4.7857\n",
      "\n",
      "Epoch 77/149\n",
      "----------\n",
      "train Loss: 0.0178 Acc: 4.9528\n",
      "Predicciones tensor([10, 10, 10,  7,  6], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  7,  6], device='cuda:0')\n",
      "val Loss: 0.2659 Acc: 4.7834\n",
      "\n",
      "Epoch 78/149\n",
      "----------\n",
      "train Loss: 0.0172 Acc: 4.9557\n",
      "Predicciones tensor([10, 10, 10,  4,  5], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  4,  5], device='cuda:0')\n",
      "val Loss: 0.2960 Acc: 4.7615\n",
      "\n",
      "Epoch 79/149\n",
      "----------\n",
      "train Loss: 0.0171 Acc: 4.9538\n",
      "Predicciones tensor([10, 10, 10,  1,  0], device='cuda:0')\n",
      "Real ....... tensor([10, 10,  6,  5,  1], device='cuda:0')\n",
      "val Loss: 0.2702 Acc: 4.7850\n",
      "\n",
      "Epoch 80/149\n",
      "----------\n",
      "train Loss: 0.0184 Acc: 4.9515\n",
      "Predicciones tensor([10, 10, 10, 10,  2], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10, 10,  1], device='cuda:0')\n",
      "val Loss: 0.2582 Acc: 4.7975\n",
      "\n",
      "Epoch 81/149\n",
      "----------\n",
      "train Loss: 0.0166 Acc: 4.9541\n",
      "Predicciones tensor([10, 10,  2,  3,  1], device='cuda:0')\n",
      "Real ....... tensor([10, 10,  2,  3,  1], device='cuda:0')\n",
      "val Loss: 0.2662 Acc: 4.7927\n",
      "\n",
      "Epoch 82/149\n",
      "----------\n",
      "train Loss: 0.0185 Acc: 4.9525\n",
      "Predicciones tensor([10, 10, 10, 10,  1], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10, 10,  1], device='cuda:0')\n",
      "val Loss: 0.2484 Acc: 4.7925\n",
      "\n",
      "Epoch 83/149\n",
      "----------\n",
      "train Loss: 0.0158 Acc: 4.9560\n",
      "Predicciones tensor([10, 10,  2,  8,  1], device='cuda:0')\n",
      "Real ....... tensor([10, 10,  2,  8,  1], device='cuda:0')\n",
      "val Loss: 0.2539 Acc: 4.8044\n",
      "\n",
      "Epoch 84/149\n",
      "----------\n",
      "train Loss: 0.0155 Acc: 4.9565\n",
      "Predicciones tensor([10, 10, 10,  3,  5], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  3,  5], device='cuda:0')\n",
      "val Loss: 0.2686 Acc: 4.7993\n",
      "\n",
      "Epoch 85/149\n",
      "----------\n",
      "train Loss: 0.0153 Acc: 4.9559\n",
      "Predicciones tensor([10, 10, 10,  2,  9], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  2,  9], device='cuda:0')\n",
      "val Loss: 0.2823 Acc: 4.7818\n",
      "\n",
      "Epoch 86/149\n",
      "----------\n",
      "train Loss: 0.0165 Acc: 4.9553\n",
      "Predicciones tensor([10, 10, 10,  6,  8], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  6,  8], device='cuda:0')\n",
      "val Loss: 0.2787 Acc: 4.7974\n",
      "\n",
      "Epoch 87/149\n",
      "----------\n",
      "train Loss: 0.0156 Acc: 4.9565\n",
      "Predicciones tensor([10, 10,  2,  8,  8], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  2,  6], device='cuda:0')\n",
      "val Loss: 0.2674 Acc: 4.8004\n",
      "\n",
      "Epoch 88/149\n",
      "----------\n",
      "train Loss: 0.0155 Acc: 4.9557\n",
      "Predicciones tensor([10, 10, 10,  9,  7], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  9,  7], device='cuda:0')\n",
      "val Loss: 0.2786 Acc: 4.7869\n",
      "\n",
      "Epoch 89/149\n",
      "----------\n",
      "train Loss: 0.0148 Acc: 4.9584\n",
      "Predicciones tensor([10, 10, 10, 10,  1], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10, 10,  1], device='cuda:0')\n",
      "val Loss: 0.2447 Acc: 4.8139\n",
      "\n",
      "Epoch 90/149\n",
      "----------\n",
      "train Loss: 0.0153 Acc: 4.9563\n",
      "Predicciones tensor([10, 10, 10,  8,  7], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  8,  7], device='cuda:0')\n",
      "val Loss: 0.2511 Acc: 4.8030\n",
      "\n",
      "Epoch 91/149\n",
      "----------\n",
      "train Loss: 0.0149 Acc: 4.9582\n",
      "Predicciones tensor([10, 10, 10,  3,  9], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  3,  9], device='cuda:0')\n",
      "val Loss: 0.2834 Acc: 4.7909\n",
      "\n",
      "Epoch 92/149\n",
      "----------\n",
      "train Loss: 0.0163 Acc: 4.9546\n",
      "Predicciones tensor([10, 10, 10, 10,  9], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10, 10,  9], device='cuda:0')\n",
      "val Loss: 0.2530 Acc: 4.8072\n",
      "\n",
      "Epoch 93/149\n",
      "----------\n",
      "train Loss: 0.0161 Acc: 4.9549\n",
      "Predicciones tensor([10, 10, 10,  2,  8], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  2,  8], device='cuda:0')\n",
      "val Loss: 0.2561 Acc: 4.7974\n",
      "\n",
      "Epoch 94/149\n",
      "----------\n",
      "train Loss: 0.0131 Acc: 4.9604\n",
      "Predicciones tensor([10, 10, 10,  3,  0], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  3,  0], device='cuda:0')\n",
      "val Loss: 0.2765 Acc: 4.7967\n",
      "\n",
      "Epoch 95/149\n",
      "----------\n",
      "train Loss: 0.0152 Acc: 4.9566\n",
      "Predicciones tensor([10, 10, 10,  3,  0], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  3,  0], device='cuda:0')\n",
      "val Loss: 0.2639 Acc: 4.7917\n",
      "\n",
      "Epoch 96/149\n",
      "----------\n",
      "train Loss: 0.0143 Acc: 4.9579\n",
      "Predicciones tensor([10, 10, 10,  2,  6], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  2,  6], device='cuda:0')\n",
      "val Loss: 0.2585 Acc: 4.8063\n",
      "\n",
      "Epoch 97/149\n",
      "----------\n",
      "train Loss: 0.0140 Acc: 4.9583\n",
      "Predicciones tensor([10, 10, 10,  2,  2], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  2,  2], device='cuda:0')\n",
      "val Loss: 0.2696 Acc: 4.7984\n",
      "\n",
      "Epoch 98/149\n",
      "----------\n",
      "train Loss: 0.0136 Acc: 4.9594\n",
      "Predicciones tensor([10, 10, 10,  2,  8], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  2,  8], device='cuda:0')\n",
      "val Loss: 0.2838 Acc: 4.7863\n",
      "\n",
      "Epoch 99/149\n",
      "----------\n",
      "train Loss: 0.0130 Acc: 4.9599\n",
      "Predicciones tensor([10, 10, 10,  8,  9], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  8,  9], device='cuda:0')\n",
      "val Loss: 0.2610 Acc: 4.8151\n",
      "\n",
      "Epoch 100/149\n",
      "----------\n",
      "train Loss: 0.0130 Acc: 4.9599\n",
      "Predicciones tensor([10, 10, 10,  1,  9], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  1,  9], device='cuda:0')\n",
      "val Loss: 0.2783 Acc: 4.8020\n",
      "\n",
      "Epoch 101/149\n",
      "----------\n",
      "train Loss: 0.0131 Acc: 4.9611\n",
      "Predicciones tensor([10, 10, 10,  4,  0], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  4,  0], device='cuda:0')\n",
      "val Loss: 0.2712 Acc: 4.7965\n",
      "\n",
      "Epoch 102/149\n",
      "----------\n",
      "train Loss: 0.0128 Acc: 4.9609\n",
      "Predicciones tensor([10, 10, 10, 10,  6], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10, 10,  6], device='cuda:0')\n",
      "val Loss: 0.2958 Acc: 4.7969\n",
      "\n",
      "Epoch 103/149\n",
      "----------\n",
      "train Loss: 0.0142 Acc: 4.9581\n",
      "Predicciones tensor([10, 10,  3,  9,  7], device='cuda:0')\n",
      "Real ....... tensor([10, 10,  2,  9,  0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2593 Acc: 4.8054\n",
      "\n",
      "Epoch 104/149\n",
      "----------\n",
      "train Loss: 0.0122 Acc: 4.9611\n",
      "Predicciones tensor([10, 10, 10, 10,  1], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10, 10,  7], device='cuda:0')\n",
      "val Loss: 0.3103 Acc: 4.7865\n",
      "\n",
      "Epoch 105/149\n",
      "----------\n",
      "train Loss: 0.0128 Acc: 4.9605\n",
      "Predicciones tensor([10, 10, 10,  3,  1], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  3,  1], device='cuda:0')\n",
      "val Loss: 0.2769 Acc: 4.7949\n",
      "\n",
      "Epoch 106/149\n",
      "----------\n",
      "train Loss: 0.0131 Acc: 4.9606\n",
      "Predicciones tensor([10, 10,  2,  3,  9], device='cuda:0')\n",
      "Real ....... tensor([10, 10,  2,  5,  9], device='cuda:0')\n",
      "val Loss: 0.2969 Acc: 4.7884\n",
      "\n",
      "Epoch 107/149\n",
      "----------\n",
      "train Loss: 0.0135 Acc: 4.9607\n",
      "Predicciones tensor([10, 10, 10, 10,  7], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10, 10,  7], device='cuda:0')\n",
      "val Loss: 0.2789 Acc: 4.7893\n",
      "\n",
      "Epoch 108/149\n",
      "----------\n",
      "train Loss: 0.0113 Acc: 4.9627\n",
      "Predicciones tensor([10, 10,  1,  2,  1], device='cuda:0')\n",
      "Real ....... tensor([10, 10,  1,  2,  1], device='cuda:0')\n",
      "val Loss: 0.2695 Acc: 4.8039\n",
      "\n",
      "Epoch 109/149\n",
      "----------\n",
      "train Loss: 0.0137 Acc: 4.9594\n",
      "Predicciones tensor([10, 10, 10,  9,  1], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  3,  1], device='cuda:0')\n",
      "val Loss: 0.2848 Acc: 4.7991\n",
      "\n",
      "Epoch 110/149\n",
      "----------\n",
      "train Loss: 0.0133 Acc: 4.9596\n",
      "Predicciones tensor([10, 10, 10,  2,  3], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  2,  3], device='cuda:0')\n",
      "val Loss: 0.2724 Acc: 4.8028\n",
      "\n",
      "Epoch 111/149\n",
      "----------\n",
      "train Loss: 0.0104 Acc: 4.9654\n",
      "Predicciones tensor([10, 10, 10,  8,  5], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  8,  5], device='cuda:0')\n",
      "val Loss: 0.2720 Acc: 4.8124\n",
      "\n",
      "Epoch 112/149\n",
      "----------\n",
      "train Loss: 0.0121 Acc: 4.9624\n",
      "Predicciones tensor([10, 10,  1,  1,  8], device='cuda:0')\n",
      "Real ....... tensor([10, 10,  1,  1,  8], device='cuda:0')\n",
      "val Loss: 0.3036 Acc: 4.7913\n",
      "\n",
      "Epoch 113/149\n",
      "----------\n",
      "train Loss: 0.0118 Acc: 4.9621\n",
      "Predicciones tensor([10, 10, 10,  8,  7], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  8,  7], device='cuda:0')\n",
      "val Loss: 0.2896 Acc: 4.8012\n",
      "\n",
      "Epoch 114/149\n",
      "----------\n",
      "train Loss: 0.0123 Acc: 4.9616\n",
      "Predicciones tensor([10, 10, 10,  7,  4], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  1,  5], device='cuda:0')\n",
      "val Loss: 0.2859 Acc: 4.8007\n",
      "\n",
      "Epoch 115/149\n",
      "----------\n",
      "train Loss: 0.0118 Acc: 4.9627\n",
      "Predicciones tensor([10, 10,  2,  0,  2], device='cuda:0')\n",
      "Real ....... tensor([10, 10,  2,  0,  2], device='cuda:0')\n",
      "val Loss: 0.2867 Acc: 4.7960\n",
      "\n",
      "Epoch 116/149\n",
      "----------\n",
      "train Loss: 0.0116 Acc: 4.9627\n",
      "Predicciones tensor([10, 10, 10,  2,  9], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  2,  9], device='cuda:0')\n",
      "val Loss: 0.2847 Acc: 4.8034\n",
      "\n",
      "Epoch 117/149\n",
      "----------\n",
      "train Loss: 0.0117 Acc: 4.9629\n",
      "Predicciones tensor([10, 10, 10,  2,  6], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  2,  6], device='cuda:0')\n",
      "val Loss: 0.2934 Acc: 4.7890\n",
      "\n",
      "Epoch 118/149\n",
      "----------\n",
      "train Loss: 0.0128 Acc: 4.9621\n",
      "Predicciones tensor([10, 10,  1,  0,  1], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  4,  0], device='cuda:0')\n",
      "val Loss: 0.2689 Acc: 4.8031\n",
      "\n",
      "Epoch 119/149\n",
      "----------\n",
      "train Loss: 0.0115 Acc: 4.9628\n",
      "Predicciones tensor([10, 10,  1,  9,  4], device='cuda:0')\n",
      "Real ....... tensor([10, 10,  1,  9,  4], device='cuda:0')\n",
      "val Loss: 0.2728 Acc: 4.8066\n",
      "\n",
      "Epoch 120/149\n",
      "----------\n",
      "train Loss: 0.0115 Acc: 4.9631\n",
      "Predicciones tensor([10, 10, 10, 10,  8], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10, 10,  8], device='cuda:0')\n",
      "val Loss: 0.2933 Acc: 4.7991\n",
      "\n",
      "Epoch 121/149\n",
      "----------\n",
      "train Loss: 0.0113 Acc: 4.9633\n",
      "Predicciones tensor([10, 10, 10,  1,  7], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  1,  7], device='cuda:0')\n",
      "val Loss: 0.2633 Acc: 4.8106\n",
      "\n",
      "Epoch 122/149\n",
      "----------\n",
      "train Loss: 0.0112 Acc: 4.9642\n",
      "Predicciones tensor([10, 10,  1,  8,  3], device='cuda:0')\n",
      "Real ....... tensor([10, 10,  1,  8,  3], device='cuda:0')\n",
      "val Loss: 0.2855 Acc: 4.8134\n",
      "\n",
      "Epoch 123/149\n",
      "----------\n",
      "train Loss: 0.0122 Acc: 4.9614\n",
      "Predicciones tensor([10, 10, 10, 10,  8], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10, 10,  8], device='cuda:0')\n",
      "val Loss: 0.2790 Acc: 4.8025\n",
      "\n",
      "Epoch 124/149\n",
      "----------\n",
      "train Loss: 0.0112 Acc: 4.9636\n",
      "Predicciones tensor([10, 10, 10,  2,  0], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  2,  0], device='cuda:0')\n",
      "val Loss: 0.2831 Acc: 4.8046\n",
      "\n",
      "Epoch 125/149\n",
      "----------\n",
      "train Loss: 0.0098 Acc: 4.9655\n",
      "Predicciones tensor([10, 10, 10,  1,  0], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  1,  0], device='cuda:0')\n",
      "val Loss: 0.2948 Acc: 4.7956\n",
      "\n",
      "Epoch 126/149\n",
      "----------\n",
      "train Loss: 0.0103 Acc: 4.9645\n",
      "Predicciones tensor([10, 10, 10,  9,  5], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  3,  5], device='cuda:0')\n",
      "val Loss: 0.2769 Acc: 4.8167\n",
      "\n",
      "Epoch 127/149\n",
      "----------\n",
      "train Loss: 0.0109 Acc: 4.9643\n",
      "Predicciones tensor([10, 10, 10,  5,  8], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  5,  8], device='cuda:0')\n",
      "val Loss: 0.2778 Acc: 4.8036\n",
      "\n",
      "Epoch 128/149\n",
      "----------\n",
      "train Loss: 0.0106 Acc: 4.9645\n",
      "Predicciones tensor([10, 10, 10,  7,  0], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  7,  1], device='cuda:0')\n",
      "val Loss: 0.2921 Acc: 4.7976\n",
      "\n",
      "Epoch 129/149\n",
      "----------\n",
      "train Loss: 0.0092 Acc: 4.9665\n",
      "Predicciones tensor([10, 10, 10,  1,  0], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  1,  0], device='cuda:0')\n",
      "val Loss: 0.3074 Acc: 4.7984\n",
      "\n",
      "Epoch 130/149\n",
      "----------\n",
      "train Loss: 0.0114 Acc: 4.9631\n",
      "Predicciones tensor([10, 10, 10,  2,  9], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  2,  4], device='cuda:0')\n",
      "val Loss: 0.2747 Acc: 4.8118\n",
      "\n",
      "Epoch 131/149\n",
      "----------\n",
      "train Loss: 0.0120 Acc: 4.9626\n",
      "Predicciones tensor([10, 10, 10,  2,  3], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  2,  3], device='cuda:0')\n",
      "val Loss: 0.2710 Acc: 4.8043\n",
      "\n",
      "Epoch 132/149\n",
      "----------\n",
      "train Loss: 0.0109 Acc: 4.9638\n",
      "Predicciones tensor([10, 10, 10,  1,  6], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  1,  6], device='cuda:0')\n",
      "val Loss: 0.3008 Acc: 4.7942\n",
      "\n",
      "Epoch 133/149\n",
      "----------\n",
      "train Loss: 0.0116 Acc: 4.9623\n",
      "Predicciones tensor([10, 10, 10,  2,  3], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  2,  3], device='cuda:0')\n",
      "val Loss: 0.2968 Acc: 4.7964\n",
      "\n",
      "Epoch 134/149\n",
      "----------\n",
      "train Loss: 0.0098 Acc: 4.9654\n",
      "Predicciones tensor([10, 10,  1,  7,  2], device='cuda:0')\n",
      "Real ....... tensor([10, 10,  9,  7,  2], device='cuda:0')\n",
      "val Loss: 0.2731 Acc: 4.8173\n",
      "\n",
      "Epoch 135/149\n",
      "----------\n",
      "train Loss: 0.0091 Acc: 4.9671\n",
      "Predicciones tensor([10, 10, 10, 10,  1], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10, 10,  1], device='cuda:0')\n",
      "val Loss: 0.2935 Acc: 4.8078\n",
      "\n",
      "Epoch 136/149\n",
      "----------\n",
      "train Loss: 0.0090 Acc: 4.9666\n",
      "Predicciones tensor([10, 10, 10,  2,  5], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  2,  5], device='cuda:0')\n",
      "val Loss: 0.2733 Acc: 4.8137\n",
      "\n",
      "Epoch 137/149\n",
      "----------\n",
      "train Loss: 0.0094 Acc: 4.9670\n",
      "Predicciones tensor([10, 10, 10, 10,  9], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10, 10,  9], device='cuda:0')\n",
      "val Loss: 0.2830 Acc: 4.8121\n",
      "\n",
      "Epoch 138/149\n",
      "----------\n",
      "train Loss: 0.0095 Acc: 4.9661\n",
      "Predicciones tensor([10, 10,  1,  2,  4], device='cuda:0')\n",
      "Real ....... tensor([10,  1,  2,  6,  8], device='cuda:0')\n",
      "val Loss: 0.2793 Acc: 4.8087\n",
      "\n",
      "Epoch 139/149\n",
      "----------\n",
      "train Loss: 0.0096 Acc: 4.9665\n",
      "Predicciones tensor([10, 10, 10, 10,  7], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10, 10,  7], device='cuda:0')\n",
      "val Loss: 0.3152 Acc: 4.7920\n",
      "\n",
      "Epoch 140/149\n",
      "----------\n",
      "train Loss: 0.0099 Acc: 4.9661\n",
      "Predicciones tensor([10, 10, 10,  6,  6], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  6,  6], device='cuda:0')\n",
      "val Loss: 0.3056 Acc: 4.8046\n",
      "\n",
      "Epoch 141/149\n",
      "----------\n",
      "train Loss: 0.0109 Acc: 4.9637\n",
      "Predicciones tensor([10, 10,  1,  4,  9], device='cuda:0')\n",
      "Real ....... tensor([10, 10,  1,  4,  9], device='cuda:0')\n",
      "val Loss: 0.2694 Acc: 4.8146\n",
      "\n",
      "Epoch 142/149\n",
      "----------\n",
      "train Loss: 0.0090 Acc: 4.9677\n",
      "Predicciones tensor([10, 10,  1,  0,  0], device='cuda:0')\n",
      "Real ....... tensor([10, 10,  1,  0,  0], device='cuda:0')\n",
      "val Loss: 0.2891 Acc: 4.8061\n",
      "\n",
      "Epoch 143/149\n",
      "----------\n",
      "train Loss: 0.0096 Acc: 4.9669\n",
      "Predicciones tensor([10, 10,  1,  1,  0], device='cuda:0')\n",
      "Real ....... tensor([10, 10,  1,  1,  0], device='cuda:0')\n",
      "val Loss: 0.2873 Acc: 4.8028\n",
      "\n",
      "Epoch 144/149\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0076 Acc: 4.9688\n",
      "Predicciones tensor([10, 10,  5,  0,  7], device='cuda:0')\n",
      "Real ....... tensor([10, 10,  5,  0,  7], device='cuda:0')\n",
      "val Loss: 0.2895 Acc: 4.8112\n",
      "\n",
      "Epoch 145/149\n",
      "----------\n",
      "train Loss: 0.0084 Acc: 4.9680\n",
      "Predicciones tensor([10, 10, 10,  3,  1], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  3,  7], device='cuda:0')\n",
      "val Loss: 0.3216 Acc: 4.7984\n",
      "\n",
      "Epoch 146/149\n",
      "----------\n",
      "train Loss: 0.0080 Acc: 4.9698\n",
      "Predicciones tensor([10, 10, 10,  2,  4], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  2,  4], device='cuda:0')\n",
      "val Loss: 0.2935 Acc: 4.8117\n",
      "\n",
      "Epoch 147/149\n",
      "----------\n",
      "train Loss: 0.0090 Acc: 4.9675\n",
      "Predicciones tensor([10, 10, 10, 10,  5], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10, 10,  5], device='cuda:0')\n",
      "val Loss: 0.2915 Acc: 4.7988\n",
      "\n",
      "Epoch 148/149\n",
      "----------\n",
      "train Loss: 0.0091 Acc: 4.9668\n",
      "Predicciones tensor([10, 10, 10,  9,  3], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  3,  3], device='cuda:0')\n",
      "val Loss: 0.2793 Acc: 4.8071\n",
      "\n",
      "Epoch 149/149\n",
      "----------\n",
      "train Loss: 0.0090 Acc: 4.9671\n",
      "Predicciones tensor([10, 10, 10,  5,  5], device='cuda:0')\n",
      "Real ....... tensor([10, 10, 10,  5,  5], device='cuda:0')\n",
      "val Loss: 0.2997 Acc: 4.8027\n",
      "\n",
      "Training complete in 127m 22s\n",
      "Best val Acc: 4.817340\n"
     ]
    }
   ],
   "source": [
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "scratch_model = vgg11_bn()\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(scratch_model)\n",
    "\n",
    "params_to_update = scratch_model.parameters()\n",
    "print(\"Params to learn:\")\n",
    "\n",
    "for name,param in scratch_model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        print(\"\\t\",name)\n",
    "\n",
    "dataloaders_dict = {\"train\":train_loader,\"val\":validation_loader}\n",
    "scratch_model = scratch_model.to(device)\n",
    "scratch_optimizer = optim.Adam(scratch_model.parameters(), lr=0.0001)\n",
    "scratch_criterion = nn.CrossEntropyLoss()\n",
    "_,scratch_hist = train_model(scratch_model, dataloaders_dict, scratch_criterion, scratch_optimizer, num_epochs=150)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for idx,data in enumerate(train_loader, 0):\n",
    "    torch.save(data,\"./\"+str(idx)+\"data.pt\")\n",
    "for idx,data in enumerate(validation_loader, 0):\n",
    "    torch.save(data,\"./\"+str(idx)+\"data_val.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './svhn_netvgg11_adam.pth'\n",
    "torch.save(scratch_model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "PATH = './svhn_netvgg11_adam.pth'\n",
    "model = vgg11_bn()\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()\n",
    "correctos = 0.0\n",
    "incorrectos = 0\n",
    "total_imagenes = 0\n",
    "for i, data in enumerate(test_loader,0):\n",
    "    image = data[\"image\"].to(device, dtype=torch.float)\n",
    "    label = data[\"labels\"].to(device, dtype=torch.long)\n",
    "    #draw_boxes(data[\"image\"][0], data[\"other\"])\n",
    "    totalbatch = len(image)\n",
    "    total_imagenes += totalbatch\n",
    "    out = model(image)\n",
    "    #print(out)\n",
    "    #print(label)\n",
    "    _,preds = torch.max(out, 1)\n",
    "    #print(predicted)\n",
    "    cor = preds.eq(label).sum()\n",
    "    #print(predicted.eq(label.float()))\n",
    "    \n",
    "    \n",
    "    correctos += cor\n",
    "    incorrectos += totalbatch*5 - (cor)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(933304, device='cuda:0') tensor(77896, device='cuda:0') 202240\n",
      "accuracy 92.29667721518987%\n"
     ]
    }
   ],
   "source": [
    "print(correctos, incorrectos, total_imagenes)\n",
    "x = ((correctos.item())/(total_imagenes*5))*100\n",
    "print(\"accuracy {}%\".format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Validation Accuracy vs. Number of Training Epochs\")\n",
    "shist = [h.cpu().numpy() for h in scratch_hist]\n",
    "plt.plot(range(1,150+1),shist,label=\"Scratch\")\n",
    "plt.xticks(np.arange(0, 151, 15.0))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cv)",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
